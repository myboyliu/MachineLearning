{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#决策树算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树是分类算法，包括ID3、C4.5、C5.0和CART四种算法，前三种属于一种方法的不同改进版本（机器学习的人研究出来的）\n",
    "\n",
    "CART：分类回归树（统计学派研究出来的算法，即可以分类，也可以回归）\n",
    "\n",
    "四个算法几乎完全一样，只不过是两种不同的流派\n",
    "\n",
    "元模型：Bagging、Boosting、随机森林\n",
    "\n",
    "分类算法是强算法，以算法取胜，元模型以量取胜；决策树是一个线性分类器，是对样本数据不断分组的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 术语\n",
    "![images](images/05/06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 根节点：一颗决策树只有一个根节点\n",
    "- 叶节点：代表一个类别\n",
    "- 中间结点：代表在一个属性上的测试\n",
    "- 分支：代表一个测试输出\n",
    "\n",
    "CART算法得到的是二叉树，ID3得到的是多叉树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 基本概念\n",
    "![images](images/05/10.png)\n",
    "\n",
    "其中s、m和l分别表示小、中和大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.1 熵与基尼系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1.1 熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$info(X)=-\\sum_{i=1}^mP(X_i)log_2P(X_i)$,$P(X_i)$表示第i个类别在整个训练元组中出现的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对上面的例子，帐号真实的记录有7条，那么$P(X) = 0.7$， 帐号不真实的概率就是0.3.帐号是否真是的熵就是$0.7 * log_2(0.7) + 0.3 * log_2(0.3) = 0.879$.如果有三个类别，那么就是三个类别中，每个类别的概率乘以以2为底的这个类别的概率的对数，然后相加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1.2 基尼系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Gini(p)=\\sum_{x=1}^Xp_x(1-p_x)=1-\\sum_{x=1}^Xp_x^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵是一个期望，越不确定，熵越大.事件的结果发生的概率越小，信息量越大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.2 条件熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(X|Y)=H(X,Y)-H(Y)=\\sum_xp(x)H(Y|X=x)$\n",
    "\n",
    "举例，问今天的下雨概率是多少，如果对这个地方不熟悉，那么概率各50%，这个时候熵是最大的。接下来告诉你这个地方现在是雨季，而且昨天下过雨，天气比较阴，那么这个时候下雨的概率就会更大，比如80%，那么熵会变小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上例中，根据日志密度来分类，可以分为下面三组数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "S S N N\n",
    "S L Y Y\n",
    "S S Y N\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三条记录，所以日志密度的概率就是$\\frac{3}{10} = 0.3$,那么P(帐号真实 | 日志密度)的概率就是$\\frac{1}{3}$\n",
    "所以对于第一组数据得出结果就是日志密度为S的条件熵为$0.3 * (\\frac{2}{3} * log_2\\frac{2}{3} + \\frac{1}{3} * log_2\\frac{1}{3})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "L M Y Y\n",
    "L M Y Y\n",
    "L M N Y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于日志是L的第二组记录，它的条件熵就是$0.3 * (\\frac{0}{3} * log_2\\frac{0}{3} + \\frac{3}{3} * log_2\\frac{3}{3})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "M M Y Y\n",
    "M L N Y\n",
    "M S N N\n",
    "M S N Y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于日志是M的第三组记录，它的条件熵就是$0.4 * (\\frac{1}{4} * log_2\\frac{1}{4} + \\frac{3}{4} * log_2\\frac{3}{4})$\n",
    "\n",
    "所以，日志密度的条件熵就是三个数相加，结果就是0.603"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.3 信息增益（互信息）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在知道了事件Y之后，X事件不确定性减少程度$Gain=熵-条件熵$\n",
    "\n",
    "针对上述例子，日志密度的信息增益就是0.276,同样的办法得到好友密度和是否使用真实头像的信息增益分别是0.033和0.553"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.4 信息增益率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益率=信息增益/熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 树的构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 选取变量的数序\n",
    "选择变量的顺序，也就是选择决策属性的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 最佳分离点（边界值）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3 树的修剪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "避免出现过拟合，过拟合表示跟当前的样本拟合的很好，但是用在别的样本上，完全不能用，不能一般化的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4 具体算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID3：信息增益、没有修剪、处理离散特征,基于奥卡姆剃刀原理,(Iterative Dichotomiser 3，迭代二叉树3代)\n",
    "- C4.5：信息增益率、悲观剪枝法、处理离散和连续特征--主流算法\n",
    "- C5.0：信息增益率、自适应增强\n",
    "- CART：基尼指数、代价复杂度剪枝法，处理离散和连续特征--主流算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 算法举例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}