{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数优化方法\n",
    "学习器模型中一般有两类参数\n",
    "- 模型参数：可以从数据中学习估计得到\n",
    "- 超参数：无法从数据中估计，只能靠人的经验进行设计指定。比如SVM里面的C、Kernel、$\\gamma$，朴素贝叶斯里的$\\alpha$等\n",
    "\n",
    "可以通过```get_params()```来获取学习器的参数和取值\n",
    "\n",
    "参数空间的搜索包括\n",
    "- 学习器\n",
    "- 参数空间\n",
    "- 用于获得候选参数组合的搜索或采样方法\n",
    "- 交叉验证机制\n",
    "- 评分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============RandomizedSearchCV的结果==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 9.86 seconds for 20 candidates parameter settings.\nModel with rank: 1\nMean validation score: 0.936 (std: 0.009)\nParameters:{'max_features': 9, 'min_samples_split': 2, 'criterion': 'gini', 'bootstrap': False, 'min_samples_leaf': 3, 'max_depth': None}\n\nModel with rank: 2\nMean validation score: 0.931 (std: 0.015)\nParameters:{'max_features': 7, 'min_samples_split': 10, 'criterion': 'gini', 'bootstrap': False, 'min_samples_leaf': 1, 'max_depth': None}\n\nModel with rank: 3\nMean validation score: 0.923 (std: 0.001)\nParameters:{'max_features': 3, 'min_samples_split': 2, 'criterion': 'entropy', 'bootstrap': False, 'min_samples_leaf': 2, 'max_depth': None}\n\n===============GridSearchCV的结果==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 86.05 seconds for 216 candidates parameter settings.\nModel with rank: 1\nMean validation score: 0.940 (std: 0.008)\nParameters:{'max_features': 10, 'min_samples_split': 2, 'criterion': 'gini', 'bootstrap': False, 'min_samples_leaf': 1, 'max_depth': None}\n\nModel with rank: 2\nMean validation score: 0.934 (std: 0.005)\nParameters:{'max_features': 3, 'min_samples_split': 3, 'criterion': 'entropy', 'bootstrap': False, 'min_samples_leaf': 1, 'max_depth': None}\n\nModel with rank: 2\nMean validation score: 0.934 (std: 0.008)\nParameters:{'max_features': 10, 'min_samples_split': 3, 'criterion': 'entropy', 'bootstrap': False, 'min_samples_leaf': 1, 'max_depth': None}\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn import model_selection,datasets,ensemble\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print('Model with rank: {0}'.format(i))\n",
    "            print('Mean validation score: {0:.3f} (std: {1:.3f})'.format(results['mean_test_score'][candidate],\n",
    "                                                                         results['std_test_score'][candidate]))\n",
    "            print('Parameters:{0}'.format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "digits = datasets.load_digits()\n",
    "x, y = digits.data, digits.target\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=20)\n",
    "print('===============RandomizedSearchCV的结果==============================')\n",
    "param_dist = {'max_depth':[3, None],\n",
    "              'max_features':sp_randint(1,11),\n",
    "              'min_samples_split':sp_randint(2,11),\n",
    "              'min_samples_leaf':sp_randint(1,11),\n",
    "              'bootstrap':[True, False],\n",
    "              'criterion':['gini', 'entropy']}\n",
    "n_iter_search = 20\n",
    "random_search = model_selection.RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search)\n",
    "start = time()\n",
    "random_search.fit(x, y)\n",
    "print('RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.' % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "print('===============GridSearchCV的结果==============================')\n",
    "param_grid = {'max_depth':[3, None],\n",
    "              'max_features':[1,3,10],\n",
    "              'min_samples_split':[2,3,10],\n",
    "              'min_samples_leaf':[1,3,10],\n",
    "              'bootstrap':[True, False],\n",
    "              'criterion':['gini', 'entropy']}\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(x, y)\n",
    "print('GridSearchCV took %.2f seconds for %d candidates parameter settings.' % ((time() - start, len(grid_search.cv_results_['params']))))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机搜索的运行时间比网格搜索显著的少，随机搜索得到的超参数组合的性能稍差一些，但这很大程度上时候噪声引起的\n",
    "优化方法\n",
    "- 指定一个合适的目标测度对模型进行评估\n",
    "- 使用SKLearn的PipeLine将estimators和他们的参数空间结合起来\n",
    "- 合理划分数据集。model_selection.train_test_split()来搞定\n",
    "- 在参数节点的计算上可以做到并行计算，通过参数n_jobs来指定\n",
    "- 提高在某些参数节点上发生错误时的鲁棒性：在出错节点上只提示警告，error_score=0来搞定"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}