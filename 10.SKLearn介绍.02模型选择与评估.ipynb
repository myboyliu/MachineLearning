{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型选择与评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 数据集划分方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 K折交叉验证\n",
    "在机器学习中，将数据集A分为训练集（training set）B和测试集（test set）C，在样本量不充足的情况下，为了充分利用数据集对算法效果进行测试，将数据集A随机分为k个不相交包，每次将其中一个包作为测试集，剩下k-1个包作为训练集进行训练，可以得到k个学习器，然后求出这k次的分类率平均值作为该模型的真实分类率\n",
    "- KFold\n",
    "- GroupKFold\n",
    "- StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index: [3 4 5] , Test Index: [0 1 2]\nTrain Index: [0 1 2] , Test Index: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "x = np.array([[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]])\n",
    "y = np.array([1,2,3,4,5,6])\n",
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print('Train Index:', train_index, ', Test Index:', test_index)\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 留一法\n",
    "留一法就是每次只留下一个样本做测试集，其它样本做训练集，如果有k个样本，则需要训练k次，测试k次。留一发计算最繁琐，但样本利用率最高。适合于小样本的情况。最有用所有分类器的平均值来衡量模型的性能\n",
    "\n",
    "如果留下P个样本，那就是留P法\n",
    "- LeaveOneOut\n",
    "- LeaveOneGroupOut\n",
    "- LeavePOut\n",
    "- LeavePGroupsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.3 随机划分\n",
    "- ShuffleSplit\n",
    "- GroupShuffleSplit\n",
    "- StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 超参数优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.1 超参数Hyper-Parameters\n",
    "学习器模型中一般有两类参数\n",
    "- 模型参数：可以从数据中学习估计得到\n",
    "- 超参数：无法从数据中估计，只能靠人的经验进行设计指定。比如SVM里面的C、Kernel、$\\gamma$，朴素贝叶斯里的$\\alpha$等\n",
    "\n",
    "可以通过```get_params()```来获取学习器的参数和取值\n",
    "\n",
    "参数空间的搜索包括\n",
    "- 学习器\n",
    "- 参数空间\n",
    "- 用于获得候选参数组合的搜索或采样方法\n",
    "- 交叉验证机制\n",
    "- 评分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============RandomizedSearchCV的结果==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 7.85 seconds for 20 candidates parameter settings.\nModel with rank: 1\nMean validation score: 0.928 (std: 0.010)\nParameters:{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 8, 'bootstrap': False, 'min_samples_leaf': 1, 'max_features': 4}\n\nModel with rank: 2\nMean validation score: 0.927 (std: 0.016)\nParameters:{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 8, 'bootstrap': False, 'min_samples_leaf': 2, 'max_features': 6}\n\nModel with rank: 2\nMean validation score: 0.927 (std: 0.009)\nParameters:{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 4, 'bootstrap': False, 'min_samples_leaf': 1, 'max_features': 5}\n\n===============GridSearchCV的结果==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 63.49 seconds for 216 candidates parameter settings.\nModel with rank: 1\nMean validation score: 0.934 (std: 0.014)\nParameters:{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 3, 'bootstrap': False, 'min_samples_leaf': 1, 'max_features': 10}\n\nModel with rank: 2\nMean validation score: 0.934 (std: 0.016)\nParameters:{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'bootstrap': False, 'min_samples_leaf': 1, 'max_features': 3}\n\nModel with rank: 3\nMean validation score: 0.933 (std: 0.008)\nParameters:{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 3, 'bootstrap': False, 'min_samples_leaf': 3, 'max_features': 3}\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn import model_selection,datasets,ensemble\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print('Model with rank: {0}'.format(i))\n",
    "            print('Mean validation score: {0:.3f} (std: {1:.3f})'.format(results['mean_test_score'][candidate],\n",
    "                                                                         results['std_test_score'][candidate]))\n",
    "            print('Parameters:{0}'.format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "digits = datasets.load_digits()\n",
    "x, y = digits.data, digits.target\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=20)\n",
    "print('===============RandomizedSearchCV的结果==============================')\n",
    "param_dist = {'max_depth':[3, None],\n",
    "              'max_features':sp_randint(1,11),\n",
    "              'min_samples_split':sp_randint(2,11),\n",
    "              'min_samples_leaf':sp_randint(1,11),\n",
    "              'bootstrap':[True, False],\n",
    "              'criterion':['gini', 'entropy']}\n",
    "n_iter_search = 20\n",
    "random_search = model_selection.RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search)\n",
    "start = time()\n",
    "random_search.fit(x, y)\n",
    "print('RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.' % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "print('===============GridSearchCV的结果==============================')\n",
    "param_grid = {'max_depth':[3, None],\n",
    "              'max_features':[1,3,10],\n",
    "              'min_samples_split':[2,3,10],\n",
    "              'min_samples_leaf':[1,3,10],\n",
    "              'bootstrap':[True, False],\n",
    "              'criterion':['gini', 'entropy']}\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(x, y)\n",
    "print('GridSearchCV took %.2f seconds for %d candidates parameter settings.' % ((time() - start, len(grid_search.cv_results_['params']))))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机搜索的运行时间比网格搜索显著的少，随机搜索得到的超参数组合的性能稍差一些，但这很大程度上时候噪声引起的\n",
    "优化方法\n",
    "- 指定一个合适的目标测度对模型进行评估\n",
    "- 使用SKLearn的PipeLine将estimators和他们的参数空间结合起来\n",
    "- 合理划分数据集。model_selection.train_test_split()来搞定\n",
    "- 在参数节点的计算上可以做到并行计算，通过参数n_jobs来指定\n",
    "- 提高在某些参数节点上发生错误时的鲁棒性：在出错节点上只提示警告，error_score=0来搞定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 模型验证方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 通过交叉验证计算得分\n",
    "```\n",
    "model_selection.cross_val_score(estimator,x)\n",
    "```\n",
    "estimator是一个实现了fit函数的学习器。有多少个交叉验证，就会返回多少个得分\n",
    "\n",
    "代码可以参考<06.聚类算法-01KMeans-SKLearn实现版本>的第二个例子代码，可以看到过了$10^{-4}$，CV得分会突然增大，所以我们应该选择大于$10^{-4}$的某一个值，而不是其它"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 对每个输入数据点产生交叉验证估计\n",
    "```\n",
    "model_selection.cross_val_predict(estimator,x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.3 计算并绘制模型的学习率曲线\n",
    "```\n",
    "model_selection.learning_curve(estimator, x, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4 计算并绘制模型的验证曲线\n",
    "```\n",
    "model_selection.validation_curve(estimator,...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.5 通过排序评估交叉验证得分的重要性\n",
    "```\n",
    "model_selection.permutation_test_score(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}