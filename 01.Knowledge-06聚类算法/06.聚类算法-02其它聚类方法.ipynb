{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其它聚类方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 层次聚类方法\n",
    "层次聚类方法对给定的数据集进行层次的分解，知道某种条件满足为止，具体又分为：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 凝聚的层次聚类\n",
    "AGNES算法(AGglomerative NESting)，一种自底向上的策略，首先将每个对象作为一个簇,然后合并这些原子簇为越来越大的簇，知道某个终结条件被满足。\n",
    "\n",
    "最初将每个对象作为一个簇，然后这些簇根据某些准则被一步步地合并。两个簇间的距离由这两个不同簇中距离最近的数据点对的相似度来确定；聚类的合并过程反复进行知道所有的对象最终满足簇的数目\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过最小距离、最大距离和平均距离来定义两个簇$A_i,A_j$的相似度或距离\n",
    "- 最小距离：两个集合中最近的两个样本的距离，容易形成链状结构\n",
    "- 最大距离：两个集合中最严的两个样本的距离，若存在异常值则不稳定\n",
    "- 平均距离：两个集合中样本间两两距离的平均值，两个集合中样本间两两距离的平方和ward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 分裂的层次聚类\n",
    "DIANA算法(DIvisive ANAlysis)，采用自顶向下的策略，它首先将所有对象至于一个簇中，然后逐渐细分为越来越小的簇，知道达到了某个终结条件。\n",
    "\n",
    "首先将所有的对象初始化到一个簇中，然后根据一些原则(比如最大的欧氏距离)，将该簇分类。知道到达用户指定的簇数目或者两个簇之间的距离超过了某个阀值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 密度聚类方法\n",
    "密度聚类方法的指导思想是，只要样本点的密度大于某阀值，则将该样本添加到最近的簇中。这类算法能克服基于距离的算法只能发现\"类圆形\"的聚类的缺点，可发现任意形状的聚类，且对噪声数据不敏感。但计算密度单元的计算复杂度大，需要建立空间索引来降低计算量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.1 DBSCAN算法\n",
    "Density-Based Spatial Clustering of Applications with Noise.一个比较有代表性的基于密度的聚类算法。 与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可在有“噪声” 的数据中发现任意形状的聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2.1 基本概念\n",
    "- 对象的$\\epsilon$-邻域:给定对象在半径$\\epsilon$内的区域\n",
    "- 核心对象:对于给定的数目m，如果一个对象的$\\epsilon$-邻域至少包含m个对象，则称该对象为核心对象。\n",
    "- 直接密度可达:给定一个对象集合D，如果p是在q的$\\epsilon$-邻域内，而q是一个核心对象，我们说对象p从对象q出发是直接密度可达的。\n",
    "- 密度可达:如果存在一个对象链$p_1,p_2,...,p_n,p_1=q,p_n=p$，对$p_i \\in D, 1 \\leq i \\leq n$,$p_{i+1}$是从$p_i$关于$\\epsilon$和m直接密度可达的，则对象p是从对象q关于$\\epsilon$和m密度可达的。\n",
    "- 密度相连:如果对象集合D中存在一个对象o，使得对象p和q是从o关于$\\epsilon$和m密度可达的，那么对象p和q是关于$\\epsilon$和m密度 相连的。\n",
    "- 簇:一个基于密度的簇是最大的密度相连对象的集合。\n",
    "- 噪声:不包含在任何簇中的对象称为噪声。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images](../images/06/03.png)\n",
    "如图$\\epsilon$=1cm，m=5，q是一个核心对象，从对象q出发到对象p是直接密度可达的\n",
    "![images](../images/06/04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2.2 算法流程\n",
    "- 如果一个点p的$\\epsilon$-邻域包含多于m个对象，则创建一个p作为核心对象的新簇;\n",
    "- 寻找并合并核心对象直接密度可达的对象\n",
    "- 没有新点可以更新簇时，算法结束\n",
    "\n",
    "由这个算法可以知道\n",
    "- 每个簇至少包含一个核心对象;\n",
    "- 非核心对象可以是簇的一部分，构成了簇的边缘(edge);\n",
    "- 包含过少对象的簇被认为是噪声"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.2 密度最大值算法\n",
    "密度最大值聚类是一种简洁优美的聚类算法, 可以识别各种形状的类簇, 并且参数很容易确定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.1 定义\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1.1 局部密度\n",
    "$\\rho_i=\\sum_j\\chi(d_{ij}-d_c)$，其中$\\chi(x)=\\begin{cases}\n",
    "1 & x < 0\\\\\n",
    "0 & otherwise\n",
    "\\end{cases}$,$d_c$是一个截断距离,$\\rho_i$即到对象i的距离小于$d_c$的对象的个数。由于该算法只对$\\rho_i$的相对值敏感, 所以对$d_c$的选择是稳健的，一种推荐做法是选择$d_c$，使得平均每个点的邻 居数为所有点的1%-2%\n",
    "\n",
    "局部密度有三种定义方式\n",
    "- 截断值：$\\rho_i=\\sum_j\\chi(d_{ij}-d_c)$，其中$\\chi(x)=\\begin{cases}\n",
    "1 & x < 0\\\\\n",
    "0 & otherwise\n",
    "\\end{cases}$\n",
    "- 高斯核相似度:$\\rho_i=\\sum_{j \\in I_S}e^{-(\\frac{d_{ij}}{d_c})^2}$\n",
    "- K近邻均值:$\\rho_i=\\frac{1}{K}\\sum_{i=1}^Kd_{ij}$，其中$d_{i1}>d_{i2}>...>d_{iK}>d_{i,K+1}>...$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1.2 高局部密度点距离$\\delta_i$\n",
    "高局部密度点距离$\\delta_i=min_{j:\\rho_j>\\rho_i}(d_{ij})$\n",
    "- 在密度高于对象i的所有对象中，到对象i最近 的距离，即高局部密度点距离\n",
    "- 对于密度最大的对象，设置$\\delta_i=max(d_{ij})$，即该问题中的无穷大。只有那些密度是局部或者全局最大的点才会有远 大于正常值的高局部密度点距离\n",
    "\n",
    "首先找到一个样本，然后计算$\\rho_i$，接着计算其它样本的$\\rho$，找到那些$\\rho > \\rho_i$的样本点，然后计算找到的这些点与初始化样本的距离，然后找到一个这些距离中的最小的那一个距离。\n",
    "\n",
    "比如每个人的财富值是$\\rho$，那么我们就是要找到比我财富大的离我最近的那个人。但是这里有个问题，比如马云，他的$\\delta$是没有的，因为没有人比他的财富更多，这个就是密度最大的对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1.3 簇中心的识别\n",
    "$\\rho$很大，说明这个点周围有好多好多样本。$\\delta$很大，说明密度比这个点的那个点，离这个点很远很远\n",
    "如果$\\rho$很小，$\\delta$很大，说明这个点是噪声，因为说明这个点离那个比他密度大的点很远，可是它周围的点又很少，那它肯定是噪声\n",
    "\n",
    "- 那些有着比较大的局部密度$\\rho_i$和很大的高密 距离$\\delta_i$的点被认为是簇的中心;\n",
    "- 高密距离$\\delta_i$较大但局部密度$\\rho_i$较小的点是异常点;\n",
    "- 确定簇中心之后，其他点按照距离已知簇的中心最近进行分类.也可按照密度可达的方法进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.2 决策图Decision Graph\n",
    "![images](../images/06/05.png)\n",
    "左图是所有点在二维空间的分布, 右图是以$\\rho$为横坐 标, 以$\\delta$为纵坐标绘制的决策图。可以看到，1和10 两个点的$\\rho_i$和$\\delta_i$都比较大，作为簇的中心点。26、 27、28三个点的$\\delta_i$也比较大，但是$\\rho_i$较小，所以是异常点，也就是噪声"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.3 边界和噪声的重认识\n",
    "- 在聚类分析中，通常需要确定每个点划分给某个簇的可靠性\n",
    "- 在该算法中，可以首先为每个簇定义一个边界区域 (border region)，亦即划分给该簇但是距离其他簇的点的距离小于$d_c$的点的集合。然后为每个簇找到其边界区域的局部密度最大的点，令其局部密度为$\\rho_h$\n",
    "- 该簇中所有局部密度大于$\\rho_h$的点被认为是簇核心的一部分(亦即将该点划分给该类簇的可靠性很大)，其余的点被认为是该类簇的光晕(halo)，亦即可以认为是噪声"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 谱聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 谱\n",
    "方阵的谱：方阵作为线性算子，它的所有特征值的全体。\n",
    "- 方阵的谱半径为最大的特征值\n",
    "- 矩阵A的谱半径:$A^TA$的最大特征值\n",
    "\n",
    "谱聚类是一种基于图论的聚类方法，通过对样本数据的拉普拉斯矩阵的特征向量进行聚类，从而达到对样本数据聚类的目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 谱分析的整体过程\n",
    "1. 给定一组数据$x_1,x_2,...,x_n$，记任意两个点之间的相似度(\"距离”的减函数)为$s_{ij}=<x_i,x_j>$， 形成相似度图(similarity graph):G=(V,E) 。 如果$x_i$和$x_j$之间的相似度$s_{ij}$大于一定的阈值，那么两个点是连接的，权值记做$s_{ij}$。\n",
    "2. 接下来，可以用相似度图来解决样本数据的聚类问题:找到图的一个划分，形成若干个组(Group)，使得不同组之间有较低的权值，组内有较高的权值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3 邻接矩阵\n",
    "给定一组样本$x_1,x_2,...,x_n$，那么对于样本$x_i,x_j$来度量它们的相似度$\\omega_{ij}$，根据高斯相似度，可以得到$\\omega_{ij}=e^{-\\frac{||x_i-x_j||_2^2}{2\\sigma^2}}$，根据这个公式，我们可以求任意两个样本的高斯相似度，从而得到了一个$n*n$的矩阵，其中对角线为1，其余为$\\omega_{ij}$，我们将对角线清零，可以得到邻接矩阵\n",
    "\n",
    "邻接矩阵$W=\\begin{cases}\n",
    "0 & i = j\\\\\n",
    "\\omega_{ij} & i \\neq j\n",
    "\\end{cases},i,j=1,2,...,n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4 度与拉普拉斯矩阵\n",
    "顶点的度$d_i=\\sum_{j=1}^n\\omega_{ij}$，所以这就是为什么需要将对角线清零。因为对角线清零后，顶点的度就是样本这一行的相似度加和\n",
    "\n",
    "如果将邻接矩阵的对角线放置上各个顶点的度，其余清零，则得到了度矩阵D，它是一个对称阵，也是对角阵\n",
    "\n",
    "拉普拉斯矩阵：$L_{n*n} = D_{n*n} - W_{n*n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.5 谱聚类算法\n",
    "L是一个$n*n$的矩阵，n是样本个数，拉普拉斯矩阵是一个实数形成的对称矩阵，那么总可以求出它的特征值与特征向量，使得等式$L \\bullet \\overrightarrow{\\mu_i}=\\lambda_i \\bullet \\overrightarrow{\\mu_i}$。由于L是一个半正定矩阵，所以特征值$\\lambda$最小是0，剩下的都是正数，那么我们就可以有如下描述：\n",
    "\n",
    "假设$\\lambda_1,\\lambda_2,...,\\lambda_n$是拉普拉斯矩阵L的n个特征值，其中$\\lambda_1=0$，剩下的$\\lambda$是大于0的正数，同样有n个特征向量与之对应$\\overrightarrow{\\mu_1},\\overrightarrow{\\mu_2},...,\\overrightarrow{\\mu_n}$,其中每个$\\overrightarrow{\\mu_i}$都是一个列向量，那么这n个列向量可以组成一个$n*n$的矩阵，如下：\n",
    "$$\\begin{bmatrix}\n",
    "\\mu_{11}&\\mu_{12}&\\dots&\\mu_{1k}&\\dots&\\mu_{1n}\\\\\n",
    "\\mu_{21}&\\mu_{22}&\\dots&\\mu_{2k}&\\dots&\\mu_{2n}\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
    "\\mu_{n1}&\\mu_{n2}&\\dots&\\mu_{nk}&\\dots&\\mu_{nn}\\\\\n",
    "\\end{bmatrix}$$\n",
    "假设我们需要将原始样本分为K个簇，那么我们只保留上述矩阵的前K个列，后面的$n-K$个列舍弃，那么第一行的k个值就是样本1的特征，第二行就是样本2的特征，...,第n行就是第n个样本的特征，然后做K-Means聚类就可以了"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}