{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EM(期望最大)算法与高斯混合模型(GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 概述\n",
    "EM算法本质上来说是一种寻找问题最优解的优化算法，高斯混合模型是EM算法的一个典型的应用场景。\n",
    "常见的寻找问题最优解的方法：\n",
    "- EM算法\n",
    "- 梯度下降法 - 线性回归\n",
    "- 坐标上升法 - 支持向量机\n",
    "- 极大似然估计 - 逻辑回归\n",
    "\n",
    "EM算法是一个无监督算法，一种聚类的算法。这个算法思想简单，但是推导复杂。它的本质就是极大似然估计法求解未知参数的最优解。极大似然估计是求解参数的最优解，EM算法对其进行了推广，能够叫它处理更复杂的问题，这些问题中多了一些隐变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 应用场景\n",
    "- 高斯混合模型\n",
    "- K-Means聚类\n",
    "- HMM-隐马尔可夫模型\n",
    "\n",
    "比如观察人的身高，符合正态分布，那么参数就有两个$(\\mu,\\sigma^2)$,我们现在有100个男性的身高和100个女性的身高,那么求解均值和标准差的过程就是估计高斯分布的参数,可以直接根据公式$\\hat{\\mu}=\\frac{1}{n}\\sum_{i=1}^nx_i=\\overline{x}$,$\\hat{\\sigma}^2=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\overline{x})^2$.\n",
    "\n",
    "上述问题中，我们是性别已知的，但是如果我们收集了200个人的身高，而性别未知，又该如何处理？这样就涉及到了两个分布、两个分布的参数.那么首先需要先性别估计，然后才能估计高斯分布.这个时候就需要用到EM算法，性别估计的参数就是隐变量\n",
    "\n",
    "这个时候，对于每一个样本或者你抽取到的人，就有两个东西需要猜测或者估计的了，一是这个人是男的还是女的？二是男生和女生\n",
    "对应的身高的高斯分布的参数是多少？\n",
    "\n",
    "只有当我们知道了哪些人属于同一个高斯分布的时候，我们才能够对这个分布的参数作出靠谱的预测，例如刚开始的最大似然所说的\n",
    "，但现在两种高斯分布的人混在一块了，我们又不知道哪些人属于第一个高斯分布，哪些属于第二个，所以就没法估计这两个分布的\n",
    "参数。反过来，只有当我们对这两个分布的参数作出了准确的估计的时候，才能知道到底哪些人属于第一个分布，那些人属于第二个\n",
    "分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1.3 EM算法和坐标上升法的对比\n",
    "EM算法就是这样，假设我们想估计知道A和B两个参数，在开始状态下二者都是未知的，但如果知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A。可以考虑首先赋予A某种初值，以此得到B的估计值，然后从B的当前值出发，重新估计A的取值，这个过程一直持续到收敛为止。\n",
    "\n",
    "这里把每个人的完整描述看做是三元组$y_i=\\{x_i,z_{i1},z_{i2}\\}$，其中，$x_i$是第i个样本的观测值，也就是对应的这个人的身高，是可以观测到的值。$z_{i1}$和$z_{i2}$表示男生和女生这两个高斯分布中哪个被用来产生值$x_i$，就是说这两个值标\n",
    "记这个人到底是男生还是女生（的身高分布产生的）。这两个值我们是不知道的，是隐含变量。确切的说，$z_{ij}$在$x_i$由第j\n",
    "个高斯分布产生时值为1，否则为0。例如一个样本的观测值为1.8，然后他来自男生的那个高斯分布，那么我们可以将这个样本表示为{1.8, 1, 0}。如果$z_{i1}$和$z_{i2}$的值已知，也就是说每个人我已经标记为男生或者女生了，那么我们就可以利用上面说的最大似然算法来估计他们各自高斯分布的参数。但是它们未知，因此我们只能用EM算法\n",
    "\n",
    "- 坐标上升法：假设我们想估计知道A和B两个参数，在开始状态下二者都是未知的，但如果知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A\n",
    "- EM算法：首先赋予A初始值，以此得到B的估计值，然后从B的当前值触发，重新估计A的取值，这个过程一直持续到收敛为止\n",
    "\n",
    "EM算法本质上就是一个坐标上升法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.4 EM算法和K-Means算法的对比\n",
    "K-Means算法是一种聚类算法，它最后得到的结果会把样本唯一的分到一类中，而EM算法最后得到的是这个样本属于任何一种分类的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. EM算法思想\n",
    "对于未知性别的估计，高斯概率密度函数要求知道两个参数，就可以知道具体的性别；极大似然要求知道性别，就能知道高斯分布参数。这就陷入了死循环。所以就引入了EM算法。\n",
    "\n",
    "EM算法分为E(Exception)步和M(Maximization)步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1 Exception\n",
    "先随便假设各个正态分布参数(对于身高的例子来说，就是$\\mu$,$\\sigma^2$).求出多项分布参数；\n",
    "比如身高的例子，现在我们只涉及到两个高斯分布，一个是男性身高，一个是女性身高，有$H_m(\\mu_m,\\sigma^2_m)$和$H_w(\\mu_w,\\sigma^2_w)$，那我们就先假定男性身高$\\mu=170,\\sigma^2=0.1$,女性身高$\\mu=150,\\sigma^2=0.2$，那么对于一个具体的人，由于知道它的样本，根据这个假定我们就可以求出这个人是男性的概率值$P(m|x_i)$，以及是女性的概率是$P(w|x_i)$，但是这两个概率的和不一定等于1，我们需要做一个归一化操作$P(m|x_i)=\\frac{P(m|x_i)}{P(m|x_i)+P(w|x_i)}$,$P(w|x_i)=\\frac{P(m|x_i)}{P(m|x_i)+P(w|x_i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2 Maximization\n",
    "用E步得到的多项分布参数，重新估计正态分布的参数，使得联合密度的似然估计最大。这个时候，两个分布的概率就变了，接着继续调整E步和M步，如此反复直到收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 随机变量的函数的期望\n",
    "定理：设随机变量Y是随机变量X的函数$Y=g(X)$，这里g是连续函数，那么\n",
    "\n",
    "1. 若X是离散型随机变量，且X的概率分布为$P\\{X=x_i\\}=p_i, i=1,2,...,n$,则Y的期望$E(Y)=E[g(X)]=\\sum_{i=1}^ng(x_i)p_i$\n",
    "\n",
    "2. 若X是连续型随机变量，且概率密度为f(x),则Y的期望$E(Y)=E[g(x)]=\\lmoustache_{-\\infty}^{+\\infty}g(x)f(x)dx$\n",
    "\n",
    "$\\sum_{z^(i)}Q_i(z^{(i)})log\\frac{p(x^{(i)},z^{(i)}); \\theta}{Q_i(z^{(i)})}$就一个随机变量函数的期望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 EM算法推导\n",
    "假设我们有一个样本集${x^(1),...,x^(m)}$,包含m个独立的样本。但每个样本i对应的类别$z^(i)$是未知的(相当于聚类)，也即隐变量。故我们需要估计概率模型$p(x,z)$的参数$\\theta$，但是由于里面包含隐变量z，所以很难用极大似然估计求解，但如果z知道了，那我们就容易求解了。\n",
    "\n",
    "对于参数估计，我们本质上还是想获得一个使似然函数最大化的那个参数$\\theta$，现在与最大似然不同的只是似然函数式中多了一个未知的变量z。也就是说我们的目标是找到适合的$\\theta$和z让$L(\\theta)$最大。那我们也许会想，你就是多了一个未知的变量而已啊，我也可以分别对未知的$\\theta$和z分别求偏导，再令其等于$\\theta$，求解出来不也一样吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 极大似然函数\n",
    "我们知道极大似然函数为$L(\\theta)=L(x_1,x_2,...,x_n;\\theta)=\\prod_{i=1}^np(x_i;\\theta),\\theta \\in \\Theta$，为了求导方便两边取对数，有$lnL(\\theta)=\\sum_{i=1}^nlogp(x_i;\\theta)$，加入隐变量后变为:$\\sum\\limits_ilog\\sum\\limits_{z^{{i}}}p(x^{(i)}, z^{(i)}; \\theta)$。本质上，我们需要使得上述式子最大化，但是可以看到里面有“和的对数”，求导后形式会非常复杂（自己可以想象下$log(f_1(x)+ f_2(x)+ f_3(x)+…)$复合函数的求导），所以很难求解得到未知参数z和$\\theta$。那么我们转化为：$=\\sum_ilog\\sum_{z^{{i}}}Q_i(z^{(i)})*\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})}$，依然还是和的对数。我们还需要变换，根据Jensen不等式，可以有$\\geq \\sum\\limits_i\\sum\\limits_{z^{{i}}}Q_i(z^{(i)})*log\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})}$。这就变成了对数的和，求导就方便多了。由于我们需要求的是上述式子的最大值，所以只考虑什么时候相等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.2 Jenson不等式\n",
    "对于一个随机变量X：\n",
    "\n",
    "- 如果f是凸函数，那么$E[f(X)]>=f(E[X])$\n",
    "- 如果f是凹函数，那么$E[f(X)]<=f(E[X])$\n",
    "\n",
    "E就是期望\n",
    "\n",
    "我们知道$E[f(X)]=\\sum\\limits_i^np_iz_i$, 其中$\\sum\\limits_i^np_i=1$，其含义就是对于函数f(x)上每个可能取值的点的一个加权平均，那么f(E[X])的含义是，对于可能取值的X的加权平均，然后在求解函数值,$logY$是一个凹函数，如下所示的就是凹函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD+CAYAAADxhFR7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBbyfw0IMNGEgv1HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108a32cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "lineX = np.linspace(1,20, 15)\n",
    "y=np.log2(lineX)\n",
    "\n",
    "plt.figure(1, facecolor='white')\n",
    "plt.plot(lineX, y, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在需要关心的是什么时候相等。如下图所示的凸函数:![images](images/09/01.png)\n",
    "\n",
    "无论是凸函数还是凹函数，当且仅当自变量X是常数的时候，等式成立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.3 结论与推导\n",
    "由于函数$f(x)=log(x)$为凹函数(其二次导数为$-\\frac{1}{x^2}<0$),而且由于$\\sum_{z^{{i}}}Q_i(z^{(i)})*\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})}$是$\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})}$的期望。根据Jenson不等式，有$E[f(X)]<=f(E[X]) \\Rightarrow f(E[X])>=E[f(X)]$,由$\\because \\sum_zQ_i(z^{(i)})=1$,$\\therefore f(E_{z^{(i)}-Q_i}[\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})}]) \\geq E_{z^{(i)}-Q_i}[f(\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置$\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})}=C$，$\\Rightarrow p(x^{(i)}, z^{(i)}; \\theta)=Q_i(z^{(i)})C \\Rightarrow \\sum_{z=1}^np(x^{(i)}, z^{(i)}; \\theta)=\\sum_{z=1}^nQ_i(z^{(i)})C$\n",
    "\n",
    "$\\therefore \\sum_{z=1}^np(x^{(i)}, z^{(i)}; \\theta)=C*\\sum_{z=1}^nQ_i(z^{(i)})$\n",
    "\n",
    "$\\because \\sum_zQ_i(z^{(i)})=1$\n",
    "\n",
    "$\\therefore \\sum_{z=1}^np(x^{(i)}, z^{(i)}; \\theta)=C$\n",
    "\n",
    "$\\because \\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})}=C$\n",
    "\n",
    "$\\therefore Q_i(z^{(i)})=\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{C} \\Rightarrow Q_i(z^{(i)})=\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{\\sum_{z=1}^np(x^{(i)}, z^{(i)}; \\theta)}$\n",
    "\n",
    "根据全概率公式，有：$\\sum_{z=1}^np(x^{(i)}, z^{(i)}; \\theta)=p(x^{(i)};\\theta)$\n",
    "\n",
    "$\\therefore Q_i(z^{(i)})=\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{p(x^{(i)};\\theta)}$\n",
    "\n",
    "又根据条件概率公式，有$ Q_i(z^{(i)})=p(z^{(i)}|x^{(i)};\\theta)$\n",
    "所以就有了EM算法的伪代码如下:\n",
    "- 初始化分布参数$\\theta$\n",
    "- 重复以下步骤并收敛\n",
    "> - E步:$Q_i(z^{i}) := \\frac{p(x^{(i)}, z^{(i)}; \\theta)}{p(x^{(i)};\\theta)}$,固定$\\theta$优化Q\n",
    "> - M步：$\\theta := argmax_{\\theta}\\sum_i\\sum_{z^{(i)}}Q_i(z^{(i)})log\\frac{p(x^{(i)},z^{(i)}; \\theta)}{Q_i(z^{(i)})}$,固定Q优化$\\theta$\n",
    "\n",
    "M步具体的$p(x^{(i)})$，需要根据具体的模型来计算\n",
    "\n",
    "高斯混合模型可以看作M个高斯密度函数的线性组合\n",
    "\n",
    "E步要得到隐变量的分布，具体到身高的例子，就是要得到每一个样本是男性的概率是多少，是女性的概率是多少，注意归一化\n",
    "\n",
    "M步就是要得到结果，具体到身高的例子，就是要得到高斯分布的均值和标准差\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于M步，由于$Q_i(z^{i})$在E步已经得到了结果，所以M步主要是展开$p(x^{(i)},z^{(i)}; \\theta)$，具体到身高的例子，由于是高斯分布，所以推导如下：\n",
    "\n",
    "$\\sum_i\\sum_{z^(i)}Q_i(z^{(i)})log\\frac{p(x^{(i)},z^{(i)}; \\theta)}{Q_i(z^{(i)})}=\\sum_i\\sum_{z^(i)}Q_i(z^{(i)})log\\frac{p(x^{(i)},z^{(i)}; \\Phi,\\mu,\\sum)}{Q_i(z^{(i)})}$\n",
    "\n",
    "$=\\sum_{i=1}^m\\sum_{j=1}^kQ_i(z^{{i}}=j)log\\frac{p(x^{(i)}|z^{(i)}=j;\\mu,\\sum)p(z^{(i)}=j;\\Phi)}{Q(z^{(i)}=j)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.4 证明EM算法是收敛的\n",
    "假定$\\theta^t$和$\\theta^{t+1}$是EM第t次和t+1次迭代后的结果，如果我们证明了$\\varphi(\\theta^t) \\leq \\varphi(\\theta^{t+1})$，也就是说极大似然估计单调增加，那么最终我们会达到最大似然估计的最大值。\n",
    "\n",
    "证明:选定$\\theta^t$后，我们得到E步\n",
    "![images](images/06/10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6 具体解法\n",
    "E步就是根据输入的样本、均值和标准差来计算每个样本属于每一个分类的概率\n",
    "\n",
    "M步就是通过得到的这个概率，然后计算新的均值和标准差，交给E步进行下一次迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯混合模型可以看作M个高斯密度函数的线性组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}