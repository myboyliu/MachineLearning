{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播算法\n",
    "神经网络是一个模型，权值就是模型的参数，也就是模型需要学习的东西。而神经网络的连结方式、网络的层次、每层的节点数这些参数是人为事先设置的，这些参数叫做超参数。\n",
    "\n",
    "假设每个训练样本为$(\\overrightarrow{x}, \\overrightarrow{t})$，其中向量$\\overrightarrow{x}$是训练样本的特征，而$\\overrightarrow{t}$是样本的目标值![images](images/11.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 计算$y_i$\n",
    "用样本的特征$\\overrightarrow{x}$，计算出神经网络中每个隐藏层节点的输出$\\alpha_i$，以及输出层每个节点的输出$y_i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 计算每个节点的误差项$\\delta_i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.1 输出层节点\n",
    "对于输出层节点i，有$\\delta_i=y_i(1-y_i)(t_i-y_i)$，其中，$\\delta_i$是节点i的误差项，$y_i$是节点的输出值，$t_i$是样本对应于节点i的目标值。举个例子，根据上图，对于输出层节点8来说，它的输出值是$y_1$，而样本的目标值是$t_1$，带入上面的公式得到节点8的误差项应该是$\\delta_8=y_1(1-ky_1)(t_1-y_1)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.2 隐藏层节点\n",
    "$\\delta_i=\\alpha_i(1-\\alpha_i)\\sum_{k \\in outputs}\\omega_{ki}\\delta_k$,其中，$\\alpha_i$是节点i的输出值，$\\omega_{ki}$是节点i到它的下一层节点k的连接的权重，$\\delta_k$是节点i的下一层节点k的误差项。例如，对于隐藏层节点4来说，计算方法如下：$\\delta_4=\\alpha_4(1-\\alpha_4)(\\omega_{84}\\delta_8+\\omega_{94}\\delta_9)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.3 更新每个连接上的权值\n",
    "$\\omega_{ji} \\leftarrow \\omega_{ij} + \\eta\\delta_jx_{ji}$,其中，$\\omega_{ji}$是节点i到节点j的权重，$\\eta$是一个成为学习速率的常数，$\\delta_j$是节点j的误差项，$x_{ji}$是节点i传递给节点j的输入。例如，权重$\\omega_{84}$的更新方法如下:$\\omega_{84} \\leftarrow \\omega_{84} + \\eta\\delta_8\\alpha_4$,类似的，权重$\\omega_{41}$的更新方法如下$\\omega_{41} \\leftarrow \\omega_{41} + \\eta\\delta_4x_1$,偏置项的输入值永远为1，例如节点4的偏置项$\\omega_{4b}$应该按照下面的方法计算$\\omega_{4b} \\leftarrow \\omega_{4b} + \\eta\\delta_4$\n",
    "\n",
    "显然，计算一个节点的误差项，需要先计算每个与其相连的下一层节点的误差项。这就要求误差项的计算顺序必须是从输出层开始，然后反向依次计算每个隐藏层的误差项，直到与输入层相连的那个隐藏层。这就是反向传播算法的名字的含义。当所有节点的误差项计算完毕后就可以更新所有的权重"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
