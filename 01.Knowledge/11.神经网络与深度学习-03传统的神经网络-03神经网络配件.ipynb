{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络配件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 损失函数-Loss\n",
    "损失函数是影响深度学习性能最重要的因素之一。是外部世界对神经网络模型训练的直接指导。合适的损失函数能够保证深度学习模型收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 Softmax-用于分类问题\n",
    "$\\sigma(Z)_j=\\frac{e^{Z_j}}{\\sum_{k=1}^Ke^{Z_k}}, j=1,2,...,K$\n",
    "\n",
    "比如特征的目标值是[1,2,3,4,1,2,3],那么不同值之间的距离比较相近,但是经过损失函数之后变成了[0.024,0.064,0.175,0.475,0.024,0.064,0.175]，这样差别就会很大，这样分类问题的预测结果更明显"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 Cross entropy-用于回归问题\n",
    "$L(w)=\\frac{1}{N}\\sum_{n=1}^NH(p_n,q_n)=-\\frac{1}{N}\\sum_{n=1}^N[y_nlog\\hat{y_n}+(1-y_n)log(1-\\hat{y_n})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.3 自定义损失函数\n",
    "- 看中某一个属性\n",
    "单独讲某一些预测值取出活赋予不同大小的参数\n",
    "- 合并多个loss\n",
    "多目标训练任务，设置合理的loss结合方式\n",
    "- 神经网络融合\n",
    "不同神经网络loss结合，共同对网络进行训练指导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 学习率 Learning rate\n",
    "- 数值大：收敛速度快\n",
    "- 数值小：精度高\n",
    "\n",
    "选用合适的学习率的办法\n",
    "- 固定一个\n",
    "- 设置一个step不停迭代\n",
    "- Adagrad\n",
    "- RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 动量\n",
    "正常$x += -learning_rate * dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 过拟合\n",
    "模型的大部分参数能够参与运算，那么过拟合的程度就低\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.1 应对过拟合-正则化\n",
    "没有加正则化，就是\n",
    "$$Loss=\\hat{y}-y\\\\\n",
    "\\Delta{w}=\\frac{d(Loss)}{d(w)}\\\\\n",
    "w := w - \\eta\\Delta{w}$$\n",
    "假如正则化以后，\n",
    "$$Loss'=\\hat{y}-y+\\lambda \\bullet ||w^2||\\\\\n",
    "\\Delta{w}=\\frac{d(Loss)}{d(w)} + 2\\lambda \\bullet w\\\\\n",
    "w := w-\\eta\\Delta{w}-2\\eta\\lambda{w}$$\n",
    "其中$2\\eta\\lambda{w}$叫做weight decay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.2 应对过拟合-Dropout\n",
    "每次随机选择一些神经元进行计算，剩下的不进行计算，这样就可以应对过拟合，因为只有大部分神经元都的参数都接近，才能每次选取不同的神经元才会有好的结果。一般最后两个layers用一下Dropout\n",
    "\n",
    "Pooling-对于原始数据进行区域求最大值或者均值的过程，本质就是降维"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}