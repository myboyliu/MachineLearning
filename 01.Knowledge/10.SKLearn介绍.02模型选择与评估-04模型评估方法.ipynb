{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Estimator对象的score方法\n",
    "默认情况下，分类器对应于准确率accuracy，回归器对应于均方误差r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 在交叉验证中使用Scoring参数\n",
    "三类：分类器标准、聚类器标准、回归器标准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 使用sklearn.metric中的性能度量函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 分类器性能度量指标\n",
    "- 精度-召回率-F度量(Precision-Recall-F_measures)\n",
    "召回率也叫做查全率。这个系列包括计算分类器召回率得分、计算分类器精度得分、计算平均精度得分、计算精度-召回率曲线、计算fbeta得分以及计算f1得分\n",
    "- 损失函数(Loss Function)：0-1损失、对数损失。包括计算无正则化的平均hinge损失、计算平均hamming损失、对数损失(logistic损失、corss_entrpy损失)、计算0-1损失、计算二元分类问题的brier score\n",
    "- 接收机操作曲线(ROC Curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.1 一些基本概念\n",
    "![images](images/10/01.png)\n",
    "- condition positive:实际的正样本个数,CP\n",
    "- condition negative:实际的负样本个数,CN\n",
    "- Prediction Positive:预测的正样本个数,PP\n",
    "- Prediction Negative:预测的负样本个数,PN\n",
    "- True Positive:正样本预测正确的个数,TP\n",
    "- False Positive:正样本预测错误的个数,FP\n",
    "- False Negative:负样本预测错误的个数,FN\n",
    "- True Negative:负样本预测正确的个数,TN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.2 准确率 Accuracy\n",
    "准确率就是正确分类的样本比例或者数量$accuracy(y,\\hat{y})=\\frac{1}{n}\\sum_{i=1}^n\\varphi,\\varphi=\\begin{cases}\n",
    "1 & y_i = \\hat{y_i}\\\\\n",
    "0 & y_i \\neq \\hat{y_i}\n",
    "\\end{cases}$，上图而言，正确率$Accuracy=\\frac{TP+TN}{CP+CN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n2\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = [0,2,1,3]\n",
    "y_true = [0,1,2,3]\n",
    "print(metrics.accuracy_score(y_true, y_pred))\n",
    "print(metrics.accuracy_score(y_true, y_pred, normalize=False)) # 不会除以样本总数了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.3 精度 Precision\n",
    "精度，也叫做PPV:Positive Predictive Value正样本预测值\n",
    "\n",
    "$Precision=\\frac{TP}{TP+FP}:$\n",
    "\n",
    "度量了分类器不会将真正的负样本错误的分为正样本的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.4 召回率Recall\n",
    "召回率也叫做TPR:True Positive Rate，也叫做灵敏度\n",
    "\n",
    "$Recall=\\frac{TP}{TP+FN}$\n",
    "\n",
    "度量了分类器找到所有正样本的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.5 FPR:False Positive Rate\n",
    "\n",
    "$FPR=\\frac{FP}{FP+TN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.6 FNR:False Negative Rate漏检率\n",
    "\n",
    "$FNR=\\frac{FN}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.7 $F_{\\beta}$\n",
    "$F_{\\beta}=(1+\\beta^2)\\frac{precision * recall}{\\beta^2precision + recall}$\n",
    "\n",
    "是precision和recall的加权调和均值，$\\beta$越小,precision的权重就越大，达标我们更看重precision的性能表现。$\\beta=1$时，就变成了$F_1$，两者同等重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n0.5\n0.666666666667\n0.833333333333\n0.666666666667\n0.555555555556\n(array([ 0.66666667,  1.        ]), array([ 1. ,  0.5]), array([ 0.71428571,  0.83333333]), array([2, 2]))\n[ 0.66666667  0.5         1.          1.        ]\n[ 1.   0.5  0.5  0. ]\n[ 0.35  0.4   0.8 ]\n0.791666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "y_pred = [0,1,0,0]\n",
    "y_true = [0,1,0,1]\n",
    "print(metrics.precision_score(y_true, y_pred))\n",
    "print(metrics.recall_score(y_true, y_pred))\n",
    "print(metrics.f1_score(y_true, y_pred))\n",
    "print(metrics.fbeta_score(y_true, y_pred, beta=0.5))\n",
    "print(metrics.fbeta_score(y_true, y_pred, beta=1))\n",
    "print(metrics.fbeta_score(y_true, y_pred, beta=2))\n",
    "print(metrics.precision_recall_fscore_support(y_true, y_pred,beta=0.5))\n",
    "\n",
    "y_true = np.array([0,0,1,1])\n",
    "y_scores = np.array([0.1,0.4,0.35,0.8])\n",
    "precision, recall, threshold = metrics.precision_recall_curve(y_true, y_scores)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(threshold)\n",
    "print(metrics.average_precision_score(y_true, y_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.8 分类评估标准之ROC曲线\n",
    "在统计学中，ROC(Receiver Operating Characteristic)曲线是一个graphical plot，展示了当discrimination threshold变化的时候二元分类器的性能。它描述了在各种不同阀值下真正率TPR相对于假正率FPR的取值变化情况。在机器学习中，TPR也被称为灵敏度、召回率、检出率。而FPR被称为fall-out或虚警率Probability of false alarm，而且FPR=1-specifity\n",
    "\n",
    "因此，ROC曲线就是the sensitivity as function of fall-out。一般来说，如果检出概率分布和虚警概率分布已知的话，ROC曲线上的每一个点都可以这样计算出来：Y轴的检出率累计概率分布(也就是概率分布曲线从负无穷到discrimination threshold的面积)相对于X轴的虚警率的累计分布\n",
    "\n",
    "AUC是ROC曲线下的面积，AUC值越大，模型就会越好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.9 各种损失函数\n",
    "具体的损失函数介绍，可以参考<01.基础-01概述.ipynb>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 回归器性能度量指标\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3 聚类器性能度量指标\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4 两两距离测度\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}