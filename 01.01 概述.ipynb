{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Python机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. 算法分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 第一种算法分类\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.1.1 有监督学习\n",
    "有训练数据集。KNN、决策树、回归等等\n",
    "- 判别方法：决策树、支持向量机、K近邻、逻辑回归\n",
    "- 生成方法：朴素贝叶斯、HMM(隐马尔可夫模型)、GMM(高斯混合模型)\n",
    "\n",
    "判别方法可以告诉测试数据的具体分类，生成方法会告诉测试数据数据任何一个分类的概率\n",
    "\n",
    "生成模型：无穷样本->概率密度模型->产生模型->预测\n",
    "\n",
    "判别模型：有限样本->判别函数->预测模型->预测\n",
    "\n",
    "生成模型更普适、判别模型更直接；生成方法关注数据是如何产生的，寻找的是数据分布模型，判别方法关注数据的差别，寻找的是分类面；由生成模型可以得到判别式模型，但由判别式模型得不到生成式模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.1.2 无监督学习\n",
    "没有训练数据集。聚类等等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.1.3 半监督学习\n",
    "强化学习。人学走路。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 第二种分类方法\n",
    "###1.2.1 分类和回归\n",
    "预测算法，最终生成一个模型。预测的变量是连续型数据变量，就是回归；如果是离散型的数据变量，那就是分类。\n",
    "这里所说的变量，是表示类别的应变量，不是表示特征的因变量\n",
    "- 回归算法：线性回归、广义线性回归\n",
    "- 分类算法：逻辑回归、支持向量积、决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.2.2 聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.2.3 关联分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.2.4 降维\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 解决问题的框架\n",
    "定义目标、定义模型、定义损失函数、训练样本、优化。\n",
    "\n",
    "模型、目标和算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 损失函数和正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 损失函数\n",
    "- 损失：预测值和真实结果的差异\n",
    "\n",
    "我们的目标就是使得损失最小，能够标识损失的函数就是损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 过拟合\n",
    "在训练数据上表现特别好，但是应用到测试数据上就会特别差。\n",
    "\n",
    "所以损失最小不是唯一目标，因为这样会导致过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3 偏差与方差\n",
    "偏差bias:预测值的均值与实际值的差，反应的是模型本身的优劣\n",
    "\n",
    "方差variance：预测结果本身的方差，反应的事算法性能的优劣\n",
    "![images](images/01/25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过拟合=低偏差+高方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}