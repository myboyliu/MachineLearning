{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Python机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. 算法分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 第一种算法分类\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.1.1 有监督学习\n",
    "有训练数据集。KNN、决策树、回归等等\n",
    "- 判别方法：决策树、支持向量机、K近邻、逻辑回归\n",
    "- 生成方法：朴素贝叶斯、HMM(隐马尔可夫模型)、GMM(高斯混合模型)\n",
    "\n",
    "判别方法可以告诉测试数据的具体分类，生成方法会告诉测试数据数据任何一个分类的概率\n",
    "\n",
    "生成模型：无穷样本->概率密度模型->产生模型->预测\n",
    "\n",
    "判别模型：有限样本->判别函数->预测模型->预测\n",
    "\n",
    "生成模型更普适、判别模型更直接；生成方法关注数据是如何产生的，寻找的是数据分布模型，判别方法关注数据的差别，寻找的是分类面；由生成模型可以得到判别式模型，但由判别式模型得不到生成式模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.1.2 无监督学习\n",
    "没有训练数据集。聚类等等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.1.3 半监督学习\n",
    "强化学习。人学走路。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 第二种分类方法\n",
    "###1.2.1 分类和回归\n",
    "预测算法，最终生成一个模型。预测的变量是连续型数据变量，就是回归；如果是离散型的数据变量，那就是分类。\n",
    "这里所说的变量，是表示类别的应变量，不是表示特征的因变量\n",
    "- 回归算法：线性回归、广义线性回归\n",
    "- 分类算法：逻辑回归、支持向量积、决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.2.2 聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.2.3 关联分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.2.4 降维\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 解决问题的框架\n",
    "定义目标、定义模型、定义损失函数、训练样本、优化。\n",
    "\n",
    "模型、目标和算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 损失函数和正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 损失函数\n",
    "- 损失：预测值和真实结果的差异\n",
    "\n",
    "我们的目标就是使得损失最小，能够标识损失的函数就是损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 过拟合\n",
    "在训练数据上表现特别好，但是应用到测试数据上就会特别差。\n",
    "\n",
    "所以损失最小不是唯一目标，因为这样会导致过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3 偏差与方差\n",
    "偏差bias:预测值的均值与实际值的差，反应的是模型本身的优劣\n",
    "\n",
    "方差variance：预测结果本身的方差，反应的事算法性能的优劣\n",
    "![images](images/01/25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过拟合=低偏差+高方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4 损失函数的一般形式\n",
    "结构风险=经验风险+惩罚项(正则化项)\n",
    "\n",
    "$J(\\omega)=\\sum_iL(m_i(\\omega))+\\lambda{R(\\omega)}$，其中$m_i$是损失值，对于连续变量，也就是回归问题，损失项可以用预测值和真实值的差值来表示；但是对于离散型的分类问题，损失项不能简单的用差值表示，我们主要讨论分类问题，所以就有$\\begin{cases}\n",
    "m_i=y^{(i)}f_\\omega(x^{(i)})\\\\\n",
    "y^{(i)} \\in \\{-1,1\\}\\\\\n",
    "f_\\omega(x^{(i)})=\\omega^Tx^{(i)}\n",
    "\\end{cases}$\n",
    "\n",
    "$L(m_i(\\omega))$是最初始的损失函数，也就是真实值与预测值之间的差异，也叫做经验风险；$R(\\omega)$是关于回归参数的一个函数，也叫做正则化。对于岭回归，就是参数的平方函数，对于lasso回归，就是参数的绝对值函数；\n",
    "\n",
    "通常正则化分为两种：L1-参数的平方函数；L2-参数的绝对值函数\n",
    "\n",
    "L1的效果是使得模型比较简单，可以进行参数选择，还可以避免过拟合；L2只能起到一个避免过拟合的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.4.1 0-1Loss\n",
    "基线，适用于二分类问题；二分类问题一般我们计算的都是P(y=1)的概率，对于P(y=0)的概率，使用的是1-P(y=1)。其实判别方法得到的都是正例的概率，也就是我们最关心的结果。\n",
    "\n",
    "$L_{01}(m)=\\begin{cases}\n",
    "0 &m \\geq 0\\\\\n",
    "1 & m \\le 0\n",
    "\\end{cases}$\n",
    "\n",
    "m就是预测结果；当$m \\geq 0$的时候，预测$\\hat{y}=1$，否则预测$\\hat{y}=-1$,数据本来的真实值我们关心的就是$y=1$的正例情况，所以当$m \\geq 0$的时候，预测值和真实值没有差距，所以损失函数就是0，如果当$m \\le 0$，那么损失函数就是1\n",
    "\n",
    "下图针对的是y=1的情况：![images](images/01/29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.4.2 Hinge Loss-折页损失\n",
    "SVM使用的就是Hinge Loss\n",
    "\n",
    "$\\ell(y)=max(0, 1- t * y)$, y代表数据的真实分类；t代表计算出来的值，也就是m计算出来的值，约束条件为$t(x)=\\begin{cases}\n",
    "1 & m \\geq 0\\\\\n",
    "-1 & m \\le 0\n",
    "\\end{cases}$,$y \\in \\{-1,1\\}$\n",
    "\n",
    "这是单个样本的损失值，至于整体样本的损失值，为$L(y)=\\frac{1}{n}\\sum_{i=1}^n\\ell(y)$\n",
    "\n",
    "下图针对的是y=1的情况：![images](images/01/30.png)\n",
    "针对上图，可以看出当$t \\geq 1$的时候，$\\ell(y)$一直取值0，相当于对于整体的损失是没有影响的。只有当$t \\le 1$的时候，才会对整体的损失有影响.\n",
    "\n",
    "更深入以下，我们可以看到图中，t可以分为3段,分别可以得到三个预测结果。$\\hat{y}=\\begin{cases}\n",
    "1 & t \\geq 1\\\\\n",
    "1 & 0 \\leq t \\leq 1\\\\\n",
    "-1 & t \\le 0\n",
    "\\end{cases}$\n",
    "具体到SVM中，当$t \\geq 1$的时候，所对应的就是在支撑平面外面的点，这些点肯定对损失函数是没有任何影响的；当$0 \\leq t \\leq 1$，所对应的就是支撑平面上的点，这些点必然也是对损失函数没有影响；$t \\le 0$对应的就是在支撑平面中间的点，以及完全分错的那些点，只有这些点才会对损失函数有影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.4.3 Log Loss-对数损失\n",
    "逻辑回归用的就是Log Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.4.4 Exp Loss-指数Loss\n",
    "AdaBoost算法使用的就是Exp Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.4.5 Square Loss\n",
    "使用的不是很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}