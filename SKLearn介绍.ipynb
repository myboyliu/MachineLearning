{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn介绍(SciKit-Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 模块介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 监督学习\n",
    "- neighbors:近邻算法\n",
    "- svm：支持向量机\n",
    "- kernal_ridge：核岭回归\n",
    "- discriminant_analysis:判别分析\n",
    "- linear_model:广义线性模型\n",
    "- ensemble:集成方法，包括随机森林，bagging\n",
    "- tree:决策树\n",
    "- naive_bayes：朴素贝叶斯\n",
    "- cross_decomposition：交叉分解\n",
    "- gaussian_process：高斯过程\n",
    "- neural_network：多层神经网络\n",
    "- calibration:概率校准\n",
    "- isotonic：保序回归\n",
    "- feature_selection：监督特征选择\n",
    "- multiclass：多类多标签算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 无监督学习\n",
    "- decomposition:矩阵因子分解\n",
    "- cluster：聚类分析\n",
    "- manifold：流形学习\n",
    "- mixture:高斯混合模型\n",
    "- neural_network:无监督神经网络\n",
    "- density：密度估计\n",
    "- covariance：协方差估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.3 数据变换\n",
    "- preprocessing：数据预处理。包括数据缺失值的处理，数据的规范化，数据的归一化等等。比如数据原来不是标准正太分布\n",
    "- feature_extraction:特征抽取。只负责把特征提取出来\n",
    "- feature_selection:特征选择。留下好的特征，丢掉不好的特征\n",
    "- random_projection:随机投影。将特征进行空间变换,将特征映射到好处理的空间上去\n",
    "- kernel_approximation：核逼近。将特征进行空间变换,将特征映射到好处理的空间上去\n",
    "- pipeline:管道流。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 六大板块与统一调用API\n",
    "分类、回归、聚类、维数约简、特征抽取选择、数据预处理\n",
    "```Python\n",
    "estimator.fit(x_train,[y_train])\n",
    "```\n",
    "- 对于Classification、Regression和Clustering,有predict函数\n",
    "- 对于Preprocessing、Dimensionality Reduction、Feature Extraction和Feature selection，有transform函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 模型选择与评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 数据集划分方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.1 K折交叉验证\n",
    "在机器学习中，将数据集A分为训练集（training set）B和测试集（test set）C，在样本量不充足的情况下，为了充分利用数据集对算法效果进行测试，将数据集A随机分为k个不相交包，每次将其中一个包作为测试集，剩下k-1个包作为训练集进行训练，可以得到k个学习器，然后求出这k次的分类率平均值作为该模型的真实分类率\n",
    "- KFold\n",
    "- GroupKFold\n",
    "- StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index: [3 4 5] , Test Index: [0 1 2]\nTrain Index: [0 1 2] , Test Index: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "x = np.array([[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]])\n",
    "y = np.array([1,2,3,4,5,6])\n",
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print('Train Index:', train_index, ', Test Index:', test_index)\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.2 留一法\n",
    "留一法就是每次只留下一个样本做测试集，其它样本做训练集，如果有k个样本，则需要训练k次，测试k次。留一发计算最繁琐，但样本利用率最高。适合于小样本的情况。最有用所有分类器的平均值来衡量模型的性能\n",
    "\n",
    "如果留下P个样本，那就是留P法\n",
    "- LeaveOneOut\n",
    "- LeaveOneGroupOut\n",
    "- LeavePOut\n",
    "- LeavePGroupsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.3 随机划分\n",
    "- ShuffleSplit\n",
    "- GroupShuffleSplit\n",
    "- StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 超参数优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.2.1 超参数Hyper-Parameters\n",
    "学习器模型中一般有两类参数\n",
    "- 模型参数：可以从数据中学习估计得到\n",
    "- 超参数：无法从数据中估计，只能靠人的经验进行设计指定。比如SVM里面的C、Kernel、$\\gamma$，朴素贝叶斯里的$\\alpha$等\n",
    "\n",
    "可以通过```get_params()```来获取学习器的参数和取值\n",
    "\n",
    "参数空间的搜索包括\n",
    "- 学习器\n",
    "- 参数空间\n",
    "- 用于获得候选参数组合的搜索或采样方法\n",
    "- 交叉验证机制\n",
    "- 评分函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.2.2 超参数优化方法\n",
    "SKLearn提供了两种通用的参数优化方法：网格搜索、随机采样\n",
    "\n",
    "- 网格搜索交叉验证(GridSearchCV)：以穷举的方式遍历所有可能的参数组合\n",
    "- 随机采样交叉验证(RandomizedSearchCV)：依据某种分布对参数空间采样，随机的得到一些候选参数组合方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============RandomizedSearchCV的结果==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 6.68 seconds for 20 candidates parameter settings.\nModel with rank: 1\nMean validation score: 0.916 (std: 0.018)\nParameters:{'min_samples_leaf': 2, 'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'bootstrap': True, 'max_features': 3}\n\nModel with rank: 2\nMean validation score: 0.914 (std: 0.018)\nParameters:{'min_samples_leaf': 8, 'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 6, 'bootstrap': False, 'max_features': 10}\n\nModel with rank: 3\nMean validation score: 0.914 (std: 0.014)\nParameters:{'min_samples_leaf': 3, 'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'bootstrap': True, 'max_features': 7}\n\n===============GridSearchCV的结果==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 58.18 seconds for 216 candidates parameter settings.\nModel with rank: 1\nMean validation score: 0.939 (std: 0.004)\nParameters:{'min_samples_leaf': 1, 'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'bootstrap': False, 'max_features': 10}\n\nModel with rank: 2\nMean validation score: 0.936 (std: 0.013)\nParameters:{'min_samples_leaf': 1, 'criterion': 'gini', 'max_depth': None, 'min_samples_split': 3, 'bootstrap': True, 'max_features': 10}\n\nModel with rank: 3\nMean validation score: 0.930 (std: 0.020)\nParameters:{'min_samples_leaf': 3, 'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'bootstrap': False, 'max_features': 10}\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn import model_selection,datasets,ensemble\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print('Model with rank: {0}'.format(i))\n",
    "            print('Mean validation score: {0:.3f} (std: {1:.3f})'.format(results['mean_test_score'][candidate],\n",
    "                                                                         results['std_test_score'][candidate]))\n",
    "            print('Parameters:{0}'.format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "digits = datasets.load_digits()\n",
    "x, y = digits.data, digits.target\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=20)\n",
    "print('===============RandomizedSearchCV的结果==============================')\n",
    "param_dist = {'max_depth':[3, None],\n",
    "              'max_features':sp_randint(1,11),\n",
    "              'min_samples_split':sp_randint(2,11),\n",
    "              'min_samples_leaf':sp_randint(1,11),\n",
    "              'bootstrap':[True, False],\n",
    "              'criterion':['gini', 'entropy']}\n",
    "n_iter_search = 20\n",
    "random_search = model_selection.RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search)\n",
    "start = time()\n",
    "random_search.fit(x, y)\n",
    "print('RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.' % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "print('===============GridSearchCV的结果==============================')\n",
    "param_grid = {'max_depth':[3, None],\n",
    "              'max_features':[1,3,10],\n",
    "              'min_samples_split':[2,3,10],\n",
    "              'min_samples_leaf':[1,3,10],\n",
    "              'bootstrap':[True, False],\n",
    "              'criterion':['gini', 'entropy']}\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(x, y)\n",
    "print('GridSearchCV took %.2f seconds for %d candidates parameter settings.' % ((time() - start, len(grid_search.cv_results_['params']))))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机搜索的运行时间比网格搜索显著的少，随机搜索得到的超参数组合的性能稍差一些，但这很大程度上时候噪声引起的\n",
    "优化方法\n",
    "- 指定一个合适的目标测度对模型进行评估\n",
    "- 使用SKLearn的PipeLine将estimators和他们的参数空间结合起来\n",
    "- 合理划分数据集。model_selection.train_test_split()来搞定\n",
    "- 在参数节点的计算上可以做到并行计算，通过参数n_jobs来指定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3 模型验证方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}