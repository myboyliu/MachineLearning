{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单数学\n",
    "包括微积分、线性代数和矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 微积分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.1 导数\n",
    "导数的定义：$f'(a)=\\lim\\limits_{h\\to{0}}\\frac{f(a+h)-f(a)}{h}$,h是变化率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.2 常见导数\n",
    "$(x^a)'=ax^{a-1}$\n",
    "\n",
    "$(e^x)'=e^x$\n",
    "\n",
    "$(a^x)'=ln(a)a^x$\n",
    "\n",
    "$(ln(x))'=\\frac{1}{x}$\n",
    "\n",
    "$\\frac{d}{dx}sin(x)=cos(x)$\n",
    "\n",
    "$\\frac{d}{dx}cos(x)=-sin(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.3 导数法则\n",
    "加法法则：$(\\alpha{f}+\\beta{g})'=\\alpha{f}'+\\beta{g}'$\n",
    "\n",
    "乘法法则：$(fg)'=f'g+fg'$\n",
    "\n",
    "除法法则：$(\\frac{f}{g})'=\\frac{f'g-fg'}{g^2}$\n",
    "\n",
    "复合函数：$f(x)=h(g(x)), f'(x)=h'(g(x)) * g'(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算$f(x)=x^4+sin(x^2)-ln(x)e^x+7$的导数\n",
    "\n",
    "$f'(x)=4x^3+cos(x^2) * 2x - \\frac{1}{x}e^x - e^xln(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.4 梯度和Hession矩阵(以下都假设函数连续可导)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.4.1 一阶导数和梯度\n",
    "一元函数$f'(x)$,x为标量\n",
    "\n",
    "多元函数$\\nabla{f(X)}=\\frac{\\partial{f(X)}}{\\partial{X}}=\\begin{bmatrix}\n",
    "\\frac{\\partial{f(X)}}{\\partial{x_1}}\\\\\n",
    "\\frac{\\partial{f(X)}}{\\partial{x_2}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial{f(X)}}{\\partial{x_n}}\n",
    "\\end{bmatrix}$,X为矢量,求偏导的时候，需要把其它的变量当成常数,这就是梯度，对矢量求导，也就是求梯度的过程\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.4.2 二阶导数和Hession矩阵\n",
    "一元函数的二阶导数:$f''(x)$\n",
    "\n",
    "多元函数的二阶导数：$\\nabla^2f(X)=\\begin{bmatrix}\n",
    "\\frac{\\partial^2{f(X)}}{\\partial{x_1}{\\partial{x_1}}}&\\frac{\\partial^2{f(X)}}{\\partial{x_1}{\\partial{x_2}}}&\\dots&\\frac{\\partial^2{f(X)}}{\\partial{x_1}{\\partial{x_n}}}\\\\\n",
    "\\frac{\\partial^2{f(X)}}{\\partial{x_2}{\\partial{x_1}}}&\\frac{\\partial^2{f(X)}}{\\partial{x_2}{\\partial{x_2}}}&\\dots&\\frac{\\partial^2{f(X)}}{\\partial{x_2}{\\partial{x_n}}}\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
    "\\frac{\\partial^2{f(X)}}{\\partial{x_n}{\\partial{x_1}}}&\\frac{\\partial^2{f(X)}}{\\partial{x_n}{\\partial{x_2}}}&\\dots&\\frac{\\partial^2{f(X)}}{\\partial{x_n}{\\partial{x_n}}}\n",
    "\\end{bmatrix}$,这就是Hession矩阵,对称矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.5 二次型的矩阵表示\n",
    "二次型就是二次多项式，可以简单使用矩阵$X^TAX$标识，比如$x_1^2+x_2^2$可以表示为$\\begin{bmatrix}\n",
    "x_1\\\\\n",
    "x_2\n",
    "\\end{bmatrix}^T$A$\\begin{bmatrix}\n",
    "x_1\\\\\n",
    "x_2\n",
    "\\end{bmatrix}$,A是一个单位矩阵，这样写法比较简单\n",
    "\n",
    "那么二次型求梯度，则有$\\frac{\\partial{X^TAX}}{\\partial{X}}=2AX$,这样求梯度会比直接对二项式求梯度简单"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.6 泰勒级数与极值\n",
    "输入为标量的泰勒级数展开$f(x_k+\\delta)\\approx{f(x_k)}+f'(x_k)\\delta+\\frac{1}{2}f''(x_k)\\delta^2$，其中$\\delta$是一个很小的量，相当于$x_k$在周围很小的一个范围展开\n",
    "\n",
    "一阶导数如果等于0，那么这个点可能是极值点\n",
    "\n",
    "称满足$f'(x_k)=0$的点为平稳点(候选点)，此时如果还有:\n",
    "- $f''(x_k) \\ge 0, x_k$为一严格局部极小点，反之为严格局部最大点\n",
    "- $f''(x_k)=0$，可能是一个鞍点(saddle point)\n",
    "\n",
    "总结，一阶导数等于0，可能有三种情况：\n",
    "- 局部最小值点，如果$f''(x_k) \\ge 0$，那么就是局部最小点\n",
    "- 局部最大值点，如果$f''(x_k) \\le 0$，那么就是局部最大点\n",
    "- 鞍点，如果$如果$f''(x_k) = 0$,那么就是鞍点，这个时候就要考虑三阶导数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入为矢量的泰勒级数展开$f(X_k+\\Delta)\\approx{f(X_k)}+\\nabla^Tf(X_k)\\Delta+\\frac{1}{2}\\Delta^T\\nabla^2f(X_k)\\Delta$,其中$X,\\Delta$都是矢量\n",
    "\n",
    "称满足$\\nabla^Tf(X_k)=0$的点为平稳点(候选点)，此时如果还有\n",
    "- $\\nabla^2f(X_k) \\succ 0,X_k$为一严格局部极小点，反之是严格局部最大点\n",
    "- 如果$\\nabla^2f(X_k)$为不定矩阵，那么就是一个鞍点\n",
    "\n",
    "由于$\\nabla^2f(X_k)$的结果是一个Hession矩阵，$\\succ 0$的意思就是这个Hession矩阵的所有特征值都是大于0的，这就是正定矩阵(那么这个函数就是凸函数)，如果是$\\nabla^2f(X_k) \\succeq 0$，那么就是半正定矩阵，也就是所有特征值都是大于等于0的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.7 梯度下降法\n",
    "为了寻找极值点，我们需要对函数求一阶导数，但是很多情况下，函数的一阶导数等于0，根本无法求解出来，或者说求解起来极其复杂。那么我们就只能使用梯度下降法来求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.7.1 为何梯度指向了函数最大增加的方向\n",
    "我们知道泰勒级数展开为$f(X_k+\\Delta)\\approx{f(X_k)}+\\nabla^Tf(X_k)\\Delta+\\frac{1}{2}\\Delta^T\\nabla^2f(X_k)\\Delta$，$\\Delta$相当于一个方向，那么我们选择一个方向往前走，当$\\Delta=\\nabla{f(X)}$的时候，即当$\\Delta$等于f(x)的梯度的时候，$\\nabla^Tf(X_k)\\Delta=\\nabla^Tf(X_k) * \\nabla{f(X_K)}$，相当于两个向量求内积,根据内积公式$a^Tb=|a|*|b|*cos\\theta$，当两个向量是平行同方向的时候最大，所以梯度执行了函数最大增加的方向。那么当两个向量是平行反方向的时候，也就是选择负梯度，那么就是函数下降最快的方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}